{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize image data generator with rescaling\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess all test images\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess all train images\n",
    "validation_generator = validation_data_gen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model structure\n",
    "emotion_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.ocl.setUseOpenCL(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankit\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "emotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-ae419f95bfec>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  emotion_model_info = emotion_model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "448/448 [==============================] - 506s 1s/step - loss: 1.8035 - accuracy: 0.2588 - val_loss: 1.7288 - val_accuracy: 0.3098\n",
      "Epoch 2/50\n",
      "448/448 [==============================] - 481s 1s/step - loss: 1.6467 - accuracy: 0.3571 - val_loss: 1.5711 - val_accuracy: 0.4082\n",
      "Epoch 3/50\n",
      "448/448 [==============================] - 356s 794ms/step - loss: 1.5490 - accuracy: 0.4041 - val_loss: 1.4868 - val_accuracy: 0.4382\n",
      "Epoch 4/50\n",
      "448/448 [==============================] - 384s 857ms/step - loss: 1.4766 - accuracy: 0.4332 - val_loss: 1.4204 - val_accuracy: 0.4570\n",
      "Epoch 5/50\n",
      "448/448 [==============================] - 490s 1s/step - loss: 1.4191 - accuracy: 0.4600 - val_loss: 1.3794 - val_accuracy: 0.4760\n",
      "Epoch 6/50\n",
      "448/448 [==============================] - 430s 959ms/step - loss: 1.3670 - accuracy: 0.4794 - val_loss: 1.3379 - val_accuracy: 0.4954\n",
      "Epoch 7/50\n",
      "448/448 [==============================] - 375s 837ms/step - loss: 1.3236 - accuracy: 0.4985 - val_loss: 1.3043 - val_accuracy: 0.5075\n",
      "Epoch 8/50\n",
      "448/448 [==============================] - 287s 641ms/step - loss: 1.2867 - accuracy: 0.5120 - val_loss: 1.2688 - val_accuracy: 0.5201\n",
      "Epoch 9/50\n",
      "448/448 [==============================] - 270s 602ms/step - loss: 1.2487 - accuracy: 0.5269 - val_loss: 1.2554 - val_accuracy: 0.5223\n",
      "Epoch 10/50\n",
      "448/448 [==============================] - 313s 699ms/step - loss: 1.2211 - accuracy: 0.5369 - val_loss: 1.2201 - val_accuracy: 0.5382\n",
      "Epoch 11/50\n",
      "448/448 [==============================] - 251s 560ms/step - loss: 1.1937 - accuracy: 0.5514 - val_loss: 1.1948 - val_accuracy: 0.5498\n",
      "Epoch 12/50\n",
      "448/448 [==============================] - 238s 532ms/step - loss: 1.1656 - accuracy: 0.5606 - val_loss: 1.1927 - val_accuracy: 0.5480\n",
      "Epoch 13/50\n",
      "448/448 [==============================] - 238s 530ms/step - loss: 1.1333 - accuracy: 0.5742 - val_loss: 1.1616 - val_accuracy: 0.5607\n",
      "Epoch 14/50\n",
      "448/448 [==============================] - 240s 535ms/step - loss: 1.1115 - accuracy: 0.5831 - val_loss: 1.1519 - val_accuracy: 0.5668\n",
      "Epoch 15/50\n",
      "448/448 [==============================] - 283s 632ms/step - loss: 1.0857 - accuracy: 0.5923 - val_loss: 1.1429 - val_accuracy: 0.5696\n",
      "Epoch 16/50\n",
      "448/448 [==============================] - 243s 541ms/step - loss: 1.0607 - accuracy: 0.6047 - val_loss: 1.1339 - val_accuracy: 0.5723\n",
      "Epoch 17/50\n",
      "448/448 [==============================] - 239s 533ms/step - loss: 1.0421 - accuracy: 0.6143 - val_loss: 1.1333 - val_accuracy: 0.5769\n",
      "Epoch 18/50\n",
      "448/448 [==============================] - 238s 530ms/step - loss: 1.0165 - accuracy: 0.6227 - val_loss: 1.1121 - val_accuracy: 0.5866\n",
      "Epoch 19/50\n",
      "448/448 [==============================] - 239s 533ms/step - loss: 0.9905 - accuracy: 0.6317 - val_loss: 1.1124 - val_accuracy: 0.5862\n",
      "Epoch 20/50\n",
      "448/448 [==============================] - 242s 541ms/step - loss: 0.9699 - accuracy: 0.6391 - val_loss: 1.1034 - val_accuracy: 0.5956\n",
      "Epoch 21/50\n",
      "448/448 [==============================] - 270s 603ms/step - loss: 0.9484 - accuracy: 0.6479 - val_loss: 1.1150 - val_accuracy: 0.5910\n",
      "Epoch 22/50\n",
      "448/448 [==============================] - 262s 584ms/step - loss: 0.9185 - accuracy: 0.6630 - val_loss: 1.1172 - val_accuracy: 0.5897\n",
      "Epoch 23/50\n",
      "448/448 [==============================] - 240s 537ms/step - loss: 0.9025 - accuracy: 0.6638 - val_loss: 1.0878 - val_accuracy: 0.6023\n",
      "Epoch 24/50\n",
      "448/448 [==============================] - 321s 716ms/step - loss: 0.8723 - accuracy: 0.6785 - val_loss: 1.0921 - val_accuracy: 0.5991\n",
      "Epoch 25/50\n",
      "448/448 [==============================] - 262s 584ms/step - loss: 0.8488 - accuracy: 0.6885 - val_loss: 1.0876 - val_accuracy: 0.6020\n",
      "Epoch 26/50\n",
      "448/448 [==============================] - 255s 569ms/step - loss: 0.8327 - accuracy: 0.6932 - val_loss: 1.0783 - val_accuracy: 0.6041\n",
      "Epoch 27/50\n",
      "448/448 [==============================] - 253s 565ms/step - loss: 0.8060 - accuracy: 0.7048 - val_loss: 1.0890 - val_accuracy: 0.5989\n",
      "Epoch 28/50\n",
      "448/448 [==============================] - 254s 567ms/step - loss: 0.7802 - accuracy: 0.7178 - val_loss: 1.0811 - val_accuracy: 0.6062\n",
      "Epoch 29/50\n",
      "448/448 [==============================] - 256s 571ms/step - loss: 0.7541 - accuracy: 0.7252 - val_loss: 1.0879 - val_accuracy: 0.6048\n",
      "Epoch 30/50\n",
      "448/448 [==============================] - 331s 738ms/step - loss: 0.7385 - accuracy: 0.7316 - val_loss: 1.0895 - val_accuracy: 0.6098\n",
      "Epoch 31/50\n",
      "448/448 [==============================] - 549s 1s/step - loss: 0.7109 - accuracy: 0.7410 - val_loss: 1.0971 - val_accuracy: 0.6080\n",
      "Epoch 32/50\n",
      "448/448 [==============================] - 404s 901ms/step - loss: 0.6870 - accuracy: 0.7481 - val_loss: 1.1001 - val_accuracy: 0.6067\n",
      "Epoch 33/50\n",
      "448/448 [==============================] - 273s 609ms/step - loss: 0.6680 - accuracy: 0.7568 - val_loss: 1.1134 - val_accuracy: 0.6112\n",
      "Epoch 34/50\n",
      "448/448 [==============================] - 254s 566ms/step - loss: 0.6476 - accuracy: 0.7654 - val_loss: 1.0993 - val_accuracy: 0.6161\n",
      "Epoch 35/50\n",
      "448/448 [==============================] - 255s 570ms/step - loss: 0.6283 - accuracy: 0.7727 - val_loss: 1.1003 - val_accuracy: 0.6191\n",
      "Epoch 36/50\n",
      "448/448 [==============================] - 278s 620ms/step - loss: 0.6075 - accuracy: 0.7804 - val_loss: 1.1191 - val_accuracy: 0.6165\n",
      "Epoch 37/50\n",
      "448/448 [==============================] - 344s 767ms/step - loss: 0.5867 - accuracy: 0.7876 - val_loss: 1.1202 - val_accuracy: 0.6152\n",
      "Epoch 38/50\n",
      "448/448 [==============================] - 244s 544ms/step - loss: 0.5752 - accuracy: 0.7920 - val_loss: 1.1207 - val_accuracy: 0.6143\n",
      "Epoch 39/50\n",
      "448/448 [==============================] - 244s 545ms/step - loss: 0.5517 - accuracy: 0.7985 - val_loss: 1.1235 - val_accuracy: 0.6204\n",
      "Epoch 40/50\n",
      "448/448 [==============================] - 241s 539ms/step - loss: 0.5357 - accuracy: 0.8049 - val_loss: 1.1233 - val_accuracy: 0.6173\n",
      "Epoch 41/50\n",
      "448/448 [==============================] - 241s 537ms/step - loss: 0.5105 - accuracy: 0.8146 - val_loss: 1.1436 - val_accuracy: 0.6237\n",
      "Epoch 42/50\n",
      "448/448 [==============================] - 244s 544ms/step - loss: 0.5008 - accuracy: 0.8185 - val_loss: 1.1388 - val_accuracy: 0.6190\n",
      "Epoch 43/50\n",
      "448/448 [==============================] - 241s 539ms/step - loss: 0.4813 - accuracy: 0.8253 - val_loss: 1.1674 - val_accuracy: 0.6254\n",
      "Epoch 44/50\n",
      "448/448 [==============================] - 240s 536ms/step - loss: 0.4665 - accuracy: 0.8318 - val_loss: 1.1626 - val_accuracy: 0.6211\n",
      "Epoch 45/50\n",
      "448/448 [==============================] - 241s 537ms/step - loss: 0.4508 - accuracy: 0.8392 - val_loss: 1.1630 - val_accuracy: 0.6228\n",
      "Epoch 46/50\n",
      "448/448 [==============================] - 241s 538ms/step - loss: 0.4386 - accuracy: 0.8430 - val_loss: 1.1887 - val_accuracy: 0.6211\n",
      "Epoch 47/50\n",
      "448/448 [==============================] - 240s 536ms/step - loss: 0.4212 - accuracy: 0.8503 - val_loss: 1.1922 - val_accuracy: 0.6250\n",
      "Epoch 48/50\n",
      "448/448 [==============================] - 244s 545ms/step - loss: 0.4132 - accuracy: 0.8516 - val_loss: 1.1956 - val_accuracy: 0.6177\n",
      "Epoch 49/50\n",
      "448/448 [==============================] - 240s 536ms/step - loss: 0.3954 - accuracy: 0.8611 - val_loss: 1.2329 - val_accuracy: 0.6228\n",
      "Epoch 50/50\n",
      "448/448 [==============================] - 243s 543ms/step - loss: 0.3754 - accuracy: 0.8653 - val_loss: 1.2255 - val_accuracy: 0.6225\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network/model\n",
    "emotion_model_info = emotion_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=7178 // 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model structure in json file\n",
    "model_json = emotion_model.to_json()\n",
    "with open(\"emotion_model50.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model weight in .h5 file\n",
    "emotion_model.save_weights('emotion_model50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
